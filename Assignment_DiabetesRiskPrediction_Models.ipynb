{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6509a759",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a7eb69",
   "metadata": {},
   "source": [
    "##### We will be building ML models like Logistic regression, Neural network, Support vector Machine(SVM) and Decision tree and we will be doing hyperparameter tuning to predict the chance of diabetes. We will be using Recall as a performance metric to judge our models.\n",
    "\n",
    "##### We choose Recall as a performance metric to judge our models as we have to give priority to FALSE NEGATIVES. FN are the cases when our model predicts that there are no chances of Diabetes but in reality there is a high risk of getting it. I such a senario the patient is at the risk of loosing their life as he might not be aware that he has to control his surgar intake."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e407ee8a",
   "metadata": {},
   "source": [
    "### Lodaing all the required libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7287bac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akash\\Anaconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "C:\\Users\\akash\\AppData\\Local\\Temp\\ipykernel_24840\\3954063568.py:19: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from __future__ import print_function\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import MultiIndex, Int64Index\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00446d60",
   "metadata": {},
   "source": [
    "### Loading the processed training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f54d490e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('./data/X_train.csv') \n",
    "y_train = pd.read_csv('./data/y_train.csv') \n",
    "X_test = pd.read_csv('./data/X_test.csv') \n",
    "y_test = pd.read_csv('./data/y_test.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543eceea",
   "metadata": {},
   "source": [
    "### Building a dataframe to store our models performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "264e3a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame({\"model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ea1ebc",
   "metadata": {},
   "source": [
    "### Implementing Logistic Regression model with hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb5de7d",
   "metadata": {},
   "source": [
    "##### Using Randomized search to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab531c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found through Randomized Search CV: {'solver': 'liblinear', 'penalty': 'l1', 'max_iter': 984, 'l1_ratio': 0.75, 'C': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akash\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\akash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'penalty': ['l1', 'l2'], \n",
    "              'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'solver': ['liblinear', 'saga'],\n",
    "              'l1_ratio': [0.25, 0.5, 0.75],\n",
    "             'max_iter': np.arange(800, 1200)\n",
    "             }\n",
    "\n",
    "# Perform Randomized Search CV to find the best hyperparameters\n",
    "best_lregression = RandomizedSearchCV(estimator=LogisticRegression(random_state=0, solver='saga'),\n",
    "                                      scoring='recall', \n",
    "                                      param_distributions=param_grid, \n",
    "                                      cv=10, \n",
    "                                      verbose=0, \n",
    "                                      return_train_score=True, \n",
    "                                      n_iter=500, \n",
    "                                      n_jobs=-1)\n",
    "best_lregression.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found through Randomized Search CV\n",
    "print(f\"Best parameters found through Randomized Search CV: {best_lregression.best_params_}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1771ba78",
   "metadata": {},
   "source": [
    "##### Performing GridSearch over a close range of parameters that we got from Randomized search to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "831cea68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found through Grid Search CV: {'C': 10, 'max_iter': 750, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for Grid Search CV\n",
    "param_grid = { \n",
    "    'solver': [best_lregression.best_params_['solver']],\n",
    "    'penalty': [best_lregression.best_params_['penalty']],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'max_iter': np.arange(750,950)\n",
    "}\n",
    "\n",
    "# Perform Grid Search CV with the best parameters from Randomized Search CV\n",
    "grid_lregression = GridSearchCV(estimator=LogisticRegression(random_state=0, solver=best_lregression.best_params_['solver']),\n",
    "                                param_grid=param_grid,\n",
    "                                scoring='recall',\n",
    "                                cv=10,\n",
    "                                n_jobs=-1)\n",
    "grid_lregression.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found through Grid Search CV\n",
    "print(f\"Best parameters found through Grid Search CV: {grid_lregression.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b841641",
   "metadata": {},
   "source": [
    "##### Storing the performance metrics in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "719b45df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the best parameters found through Grid Search CV \n",
    "c_matrix = confusion_matrix(y_test, grid_lregression.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model': \"LR\", \n",
    "                                                     'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                     'Precision': [TP/(TP+FP)], \n",
    "                                                     'Recall': [TP/(TP+FN)], \n",
    "                                                     'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                    }, index=[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cc80e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  Accuracy  Precision    Recall        F1\n",
       "0    LR  0.916667   0.938144  0.928571  0.933333"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59e4e93",
   "metadata": {},
   "source": [
    "### Implementing SVM model with hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2238831d",
   "metadata": {},
   "source": [
    "##### Using Randomized search to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fadadf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 140 candidates, totalling 700 fits\n",
      "The best recall score is 1.0\n",
      "... with parameters: {'kernel': 'poly', 'gamma': 'scale', 'C': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'C': np.arange(1,25),   \n",
    "    'gamma': ['scale','auto'],\n",
    "    'kernel':['linear','rbf','poly']\n",
    "}\n",
    "\n",
    "svm = SVC()\n",
    "rand_search = RandomizedSearchCV(estimator = svm, param_distributions=param_grid, cv=kfolds, n_iter=140,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dba7e36",
   "metadata": {},
   "source": [
    "##### Performing GridSearch over a close range of parameters that we got from Randomized search to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dc23035",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akash\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 20.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\akash\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\akash\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 255, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\Users\\akash\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 315, in _dense_fit\n",
      "    ) = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 189, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\akash\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 1.         1.         0.99545455]\n",
      "  warnings.warn(\n",
      "C:\\Users\\akash\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [       nan 1.         1.         0.99662287]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "The best recall score is 1.0\n",
      "... with parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'poly'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "C = rand_search.best_params_['C']\n",
    "gamma = rand_search.best_params_['gamma']\n",
    "kernel = rand_search.best_params_['kernel']\n",
    "\n",
    "param_grid = {\n",
    "    'C': np.arange(C-2,C+2),  \n",
    "    'gamma': [gamma],\n",
    "    'kernel': [kernel]\n",
    "    \n",
    "}\n",
    "\n",
    "svm1 = SVC()\n",
    "grid_search = GridSearchCV(estimator = svm1, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestprecision_SVM = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b7b2c8",
   "metadata": {},
   "source": [
    "##### Storing the performance metrics in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad2e0a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.628205</td>\n",
       "      <td>0.628205</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.771654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  Accuracy  Precision    Recall        F1\n",
       "0    LR  0.916667   0.938144  0.928571  0.933333\n",
       "0   SVM  0.628205   0.628205  1.000000  0.771654"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"SVM\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd2981f",
   "metadata": {},
   "source": [
    "### Implementing Decision Tree model with hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d173302a",
   "metadata": {},
   "source": [
    "##### Using Randomized search to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fc198fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "The best recall score is 0.932020202020202\n",
      "... with parameters: {'min_samples_split': 45, 'min_samples_leaf': 15, 'min_impurity_decrease': 0.0061, 'max_leaf_nodes': 30, 'max_depth': 13, 'criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(2,50),  \n",
    "    'min_samples_leaf': np.arange(1,50),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.01, 0.0005),\n",
    "    'max_leaf_nodes': np.arange(5, 50), \n",
    "    'max_depth': np.arange(1,20), \n",
    "    'criterion': ['gini', 'entropy'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator=dtree, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                                 scoring=score_measure, verbose=1, n_jobs=-1, # n_jobs=-1 will utilize all available CPUs \n",
    "                                 return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestPrecTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817e7b40",
   "metadata": {},
   "source": [
    "##### Performing GridSearch over a close range of parameters that we got from Randomized search to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ecf1377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 320 candidates, totalling 1600 fits\n",
      "The best recall score is 0.9094949494949495\n",
      "... with parameters: {'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': 10, 'min_impurity_decrease': 0.0005, 'min_samples_leaf': 8, 'min_samples_split': 26}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(26,36),  \n",
    "    'min_samples_leaf': np.arange(8,16),\n",
    "    'min_impurity_decrease': np.arange( 0.0005, 0.0010, 0.0020),\n",
    "    'max_leaf_nodes': [10,30], \n",
    "    'max_depth': [5,15], \n",
    "    'criterion': ['entropy']\n",
    "}\n",
    "\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestPrecisionTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66773553",
   "metadata": {},
   "source": [
    "##### Storing the performance metrics in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7658ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.628205</td>\n",
       "      <td>0.628205</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.771654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.948980</td>\n",
       "      <td>0.939394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  Accuracy  Precision    Recall        F1\n",
       "0             LR  0.916667   0.938144  0.928571  0.933333\n",
       "0            SVM  0.628205   0.628205  1.000000  0.771654\n",
       "0  Decision Tree  0.923077   0.930000  0.948980  0.939394"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Decision Tree\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fb1b0f",
   "metadata": {},
   "source": [
    "### Implementing Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8f2aa3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "{'solver': 'adam', 'max_iter': 1000, 'learning_rate_init': 0.2, 'learning_rate': 'adaptive', 'hidden_layer_sizes': (50, 30), 'alpha': 0.7, 'activation': 'logistic'}\n",
      "CPU times: total: 15.4 s\n",
      "Wall time: 2min 15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akash\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (50,), (70,),(50,30), (40,20), (60,40, 20)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0, .2, .5, .7, 1],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1, 0.2],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = RandomizedSearchCV(estimator = ann, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33b9885b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.628205</td>\n",
       "      <td>0.628205</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.771654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.948980</td>\n",
       "      <td>0.939394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neural Network Randomized search</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              model  Accuracy  Precision    Recall        F1\n",
       "0                                LR  0.916667   0.938144  0.928571  0.933333\n",
       "0                               SVM  0.628205   0.628205  1.000000  0.771654\n",
       "0                     Decision Tree  0.923077   0.930000  0.948980  0.939394\n",
       "0  Neural Network Randomized search  0.794872        NaN  0.693878  0.809524"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "c_matrix = confusion_matrix(y_test, y_pred)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Neural Network Randomized search\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)],  \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5df95e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "{'activation': 'tanh', 'alpha': 0.5, 'hidden_layer_sizes': (30,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.15, 'max_iter': 1000, 'solver': 'adam'}\n",
      "CPU times: total: 3.12 s\n",
      "Wall time: 21.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akash\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (30,), (50,), (70,), (90,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [.5, .7, 1],\n",
    "    'learning_rate': ['adaptive', 'invscaling'],\n",
    "    'learning_rate_init': [0.005, 0.01, 0.15],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = GridSearchCV(estimator = ann, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d340827a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.628205</td>\n",
       "      <td>0.628205</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.771654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.948980</td>\n",
       "      <td>0.939394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neural Network Randomized search</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neural Network Grid search</td>\n",
       "      <td>0.628205</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.771654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              model  Accuracy  Precision    Recall        F1\n",
       "0                                LR  0.916667   0.938144  0.928571  0.933333\n",
       "0                               SVM  0.628205   0.628205  1.000000  0.771654\n",
       "0                     Decision Tree  0.923077   0.930000  0.948980  0.939394\n",
       "0  Neural Network Randomized search  0.794872        NaN  0.693878  0.809524\n",
       "0        Neural Network Grid search  0.628205        NaN  1.000000  0.771654"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "c_matrix = confusion_matrix(y_test, y_pred)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Neural Network Grid search\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)],  \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cb07d0",
   "metadata": {},
   "source": [
    "#### Deep Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f307724e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# define recall function as a member function of the Model class\n",
    "class Metrics(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.recall = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        y_pred = np.round(y_pred)\n",
    "        _recall = recall_score(y_test, y_pred)\n",
    "        self.recall.append(_recall)\n",
    "        print(\"val_recall:\",_recall)\n",
    "\n",
    "def recall(y_test, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_test * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_test, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d04c5f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 46.9 ms\n",
      "Wall time: 97.1 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "\n",
    "# create model stucture\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Input(16))\n",
    "model.add(keras.layers.Dense(10, activation='relu',kernel_initializer= tf.keras.initializers.GlorotNormal()))\n",
    "model.add(keras.layers.Dense(10, activation='relu', kernel_initializer= tf.keras.initializers.GlorotNormal()))\n",
    "model.add(keras.layers.Dense(10, activation='relu', kernel_initializer= tf.keras.initializers.GlorotNormal()))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "# compile the model with the custom loss function\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[recall])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f5b24e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5/5 [==============================] - 0s 5ms/steposs: 15.1756 - recall: 1.00\n",
      "val_recall: 1.0\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 15.7439 - recall: 1.0000 - val_loss: 15.1499 - val_recall: 1.0000\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 0s 3ms/steposs: 18.7185 - recall: 1.00\n",
      "val_recall: 1.0\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 14.8794 - recall: 1.0000 - val_loss: 14.2723 - val_recall: 1.0000\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 4ms/steposs: 13.3634 - recall: 1.00\n",
      "val_recall: 1.0\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 13.9661 - recall: 1.0000 - val_loss: 13.4336 - val_recall: 1.0000\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 3ms/steposs: 15.2228 - recall: 1.00\n",
      "val_recall: 1.0\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 13.1742 - recall: 1.0000 - val_loss: 12.6149 - val_recall: 1.0000\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 4ms/steposs: 12.6924 - recall: 1.00\n",
      "val_recall: 1.0\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 12.3395 - recall: 1.0000 - val_loss: 11.8347 - val_recall: 1.0000\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 851us/steps: 11.1284 - recall: 1.00\n",
      "val_recall: 1.0\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 11.5554 - recall: 1.0000 - val_loss: 11.0821 - val_recall: 1.0000\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 5ms/steposs: 13.2471 - recall: 1.00\n",
      "val_recall: 1.0\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 10.8426 - recall: 1.0000 - val_loss: 10.3486 - val_recall: 1.0000\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 0s 5ms/steposs: 9.7581 - recall: 1.00\n",
      "val_recall: 1.0\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 10.0892 - recall: 1.0000 - val_loss: 9.6512 - val_recall: 1.0000\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 2ms/steposs: 10.1351 - recall: 1.00\n",
      "val_recall: 1.0\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 9.4134 - recall: 1.0000 - val_loss: 8.9749 - val_recall: 1.0000\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 0s 2ms/steposs: 9.8102 - recall: 1.00\n",
      "val_recall: 1.0\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 8.7503 - recall: 1.0000 - val_loss: 8.3259 - val_recall: 1.0000\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 2ms/steposs: 8.5664 - recall: 1.00\n",
      "val_recall: 1.0\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 8.0937 - recall: 1.0000 - val_loss: 7.7072 - val_recall: 1.0000\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 3ms/steposs: 7.9159 - recall: 1.00\n",
      "val_recall: 1.0\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 7.4895 - recall: 1.0000 - val_loss: 7.1069 - val_recall: 1.0000\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 0s 3ms/steposs: 7.8490 - recall: 1.00\n",
      "val_recall: 1.0\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 6.8991 - recall: 1.0000 - val_loss: 6.5259 - val_recall: 1.0000\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 0s 2ms/steposs: 7.3418 - recall: 1.00\n",
      "val_recall: 1.0\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 6.3254 - recall: 1.0000 - val_loss: 5.9644 - val_recall: 1.0000\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 2ms/steposs: 6.3185 - recall: 1.00\n",
      "val_recall: 1.0\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 5.7714 - recall: 1.0000 - val_loss: 5.4220 - val_recall: 1.0000\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 0s 3ms/steposs: 4.0359 - recall: 1.00\n",
      "val_recall: 1.0\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 5.2093 - recall: 1.0000 - val_loss: 4.9058 - val_recall: 1.0000\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 0s 2ms/steposs: 5.8865 - recall: 1.00\n",
      "val_recall: 1.0\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 4.7282 - recall: 1.0000 - val_loss: 4.3914 - val_recall: 1.0000\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 0s 2ms/steposs: 4.5619 - recall: 1.00\n",
      "val_recall: 1.0\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 4.2111 - recall: 1.0000 - val_loss: 3.8965 - val_recall: 1.0000\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 0s 3ms/steposs: 3.7644 - recall: 1.00\n",
      "val_recall: 1.0\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 3.7275 - recall: 1.0000 - val_loss: 3.4499 - val_recall: 1.0000\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 0s 2ms/steposs: 3.5443 - recall: 1.00\n",
      "val_recall: 1.0\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 3.3147 - recall: 1.0000 - val_loss: 3.0567 - val_recall: 1.0000\n",
      "CPU times: total: 2.17 s\n",
      "Wall time: 4.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=100, callbacks=[Metrics()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07df0656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 2.9151 - recall: 1.0000 - val_loss: 2.6678 - val_recall: 1.0000\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.5398 - recall: 1.0000 - val_loss: 2.2752 - val_recall: 1.0000\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.1307 - recall: 1.0000 - val_loss: 1.8972 - val_recall: 1.0000\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.7740 - recall: 1.0000 - val_loss: 1.5277 - val_recall: 1.0000\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.4021 - recall: 1.0000 - val_loss: 1.1933 - val_recall: 1.0000\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.0797 - recall: 1.0000 - val_loss: 0.9162 - val_recall: 1.0000\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.8443 - recall: 1.0000 - val_loss: 0.7162 - val_recall: 1.0000\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6738 - recall: 1.0000 - val_loss: 0.6400 - val_recall: 0.9919\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6357 - recall: 1.0000 - val_loss: 0.6290 - val_recall: 0.9919\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6307 - recall: 0.9836 - val_loss: 0.6321 - val_recall: 0.9597\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6317 - recall: 0.9396 - val_loss: 0.6328 - val_recall: 0.9238\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6303 - recall: 0.9260 - val_loss: 0.6291 - val_recall: 0.9597\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6258 - recall: 0.9544 - val_loss: 0.6244 - val_recall: 0.9758\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6213 - recall: 0.9760 - val_loss: 0.6211 - val_recall: 0.9919\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6187 - recall: 0.9870 - val_loss: 0.6195 - val_recall: 0.9919\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6192 - recall: 0.9881 - val_loss: 0.6190 - val_recall: 0.9919\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6171 - recall: 0.9854 - val_loss: 0.6178 - val_recall: 0.9919\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6159 - recall: 0.9876 - val_loss: 0.6165 - val_recall: 0.9919\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6147 - recall: 0.9876 - val_loss: 0.6152 - val_recall: 0.9919\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6135 - recall: 0.9848 - val_loss: 0.6139 - val_recall: 0.9919\n",
      "CPU times: total: 359 ms\n",
      "Wall time: 1.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3500ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.628205</td>\n",
       "      <td>0.628205</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.771654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.948980</td>\n",
       "      <td>0.939394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neural Network Randomized search</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neural Network Grid search</td>\n",
       "      <td>0.628205</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.771654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deep Neural Network</td>\n",
       "      <td>0.660256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.989796</td>\n",
       "      <td>0.785425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              model  Accuracy  Precision    Recall        F1\n",
       "0                                LR  0.916667   0.938144  0.928571  0.933333\n",
       "0                               SVM  0.628205   0.628205  1.000000  0.771654\n",
       "0                     Decision Tree  0.923077   0.930000  0.948980  0.939394\n",
       "0  Neural Network Randomized search  0.794872        NaN  0.693878  0.809524\n",
       "0        Neural Network Grid search  0.628205        NaN  1.000000  0.771654\n",
       "0               Deep Neural Network  0.660256        NaN  0.989796  0.785425"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "c_matrix = confusion_matrix(y_test, y_pred)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Deep Neural Network\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)],  \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f27635",
   "metadata": {},
   "source": [
    "#### Looking at the performance metric dataframe we can see that the highest recall score of 100 percent is of SVM and Neural Network model. Although these model  has the low accuracy, precision and F1 score.  We know that no model can predict anything with 100 percent accuracy and the same goes for these models also.\n",
    "\n",
    "#### Overall we can say that DNN model is the best model for predicting that if a person is at the risk of getting Diabetes as it has a recall score of 98.9 percent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
